[ { "title": "Creating a Python Environment", "url": "/TheDataLearning/posts/Creating-Python-Environment/", "categories": "Tutorial, Python, Machine Learning", "tags": "Python, Jupyter Notebook, Machine Learning", "date": "2022-03-10 23:25:00 +0800", "snippet": "In this article, we will try to lean about creating virtual environment in Python.Creating Virtual EnvironmentCreating a virtual environment in Python is easy task. Before creating a virtual environment, make sure pip is installed and updated.pip install virtualenvUse below command in Command Prompt to create the virtual environment:virtualenv NameOfTheVirtualEnvironmentOnce the environment is created, make sure environment is activated. To activate the virtual environment, use below command:PathToVirtualEnvironment/Scripts/ActivateTo deactivate the virtual environment, use below command:PathToVirtualEnvironment/Scripts/DeactivateTo check the version of Python, use below command:python --versionThank you for reading." }, { "title": "Adding Virtual Environment to Jupyter Notebook", "url": "/TheDataLearning/posts/Adding-Virtual-environment-to-Jupyter-notebook/", "categories": "Tutorial, Python, Machine Learning", "tags": "Python, Jupyter Notebook, Machine Learning", "date": "2022-03-10 23:25:00 +0800", "snippet": "Adding a new virtual environment to Jupyter NotebookAfter we create a virtual environment, we need to add the created virtual environment to Jupyter notebook. Make sure you have activated the virtual environment and execute below code: pip install --user ipykernel Manually add the kernel / virtual environment to the Jupyter notebook: python -m ipykernel install --user --name=NewVirtualEnvironment Close the command prompt and open jupyter notebook: jupyter notebook Select the “New” dropdown and you should be able to find newly created virtual environment. Uninstalling: If you need to uninstall the kernel, we can use below command: jupyter kernelspec uninstall VirtualEnvironment " }, { "title": "Neural Networks - History", "url": "/TheDataLearning/posts/Neural-Networks-History/", "categories": "Tutorial, Machine Learning", "tags": "Machine Learning, Neural Network, Neuron", "date": "2021-04-08 23:25:00 +0800", "snippet": "In this article, I want to give brief introduction to Neural Networks.First Neural Network was designed by Frank Rosenblatt in 1957 and is called perceptron. Concept is loosely inspired from Biological neurons.Concepts of Neural networks are loosely inspired from Biological neurons (Biological neurons are more complicated). (Image from https://en.wikipedia.org/wiki/Artificial_neuron#/media/File:Neuron3.svg)On highlevel, neurons contains three parts, Dendrites -&amp;gt; Dendrites collects the impulses. Size and Width of Dendrites, determine the strength of impulse Cell body (nucleus) -&amp;gt; Nucleus collect the impulses from all the Dendrites and process information Axoms -&amp;gt; Axioms will send the information to other neuronsBiological neurons cannot exist on their own but exists in networks. Output of one neuron connects to dendrites of other neurons and forms the networks In Artificial Neural networks, we will pass inputs, x1, x2, x3,… xn with w1, w2, w3, … wn as corresponding weights to the neurons. These inputs and weights are weighted and summed and passed thru activating function. This function process the data and send the output.In 1986, Hilton and others submitted work on how to train Artificial neural networks and is called as Back Propagation algorithm. During this time, neural networks failed when number of hidden layers (between input and output layers) are more.Neural Networks gained popularity again in 2012 with ImageNet competition.Today artificial neural networks are applied in different Voice assistants, Self driving cars etc.,Hope you like this article and please share your feedback." }, { "title": "Biological Neurons", "url": "/TheDataLearning/posts/Biological-Neurons/", "categories": "Tutorial, Machine Learning", "tags": "Machine Learning, Neural Network, Neuron", "date": "2021-04-08 23:25:00 +0800", "snippet": "In this article, we will look into how Biological Neurons work and how it is different from Artificial Neurons When we observe a single neuron, some dendrites will be of more thickness than other dendrites. This allows to pass more impulses to nucleus than other dendrites.Once we have enough impulses from dendrites then neurons sends the output to axioms, else neurons will not be activated.Also, if we observe the scans of kids from newborn to 6 years, we see the connections between neurons is increasing and becoming dense upto 2 years. After 2 years connections are pruning. Kids start learning about language , shapes, objects etc., durning early age and build the neurons. After some age, these neurons starts pruning as few of the neurons (experience) will be redundant or random connections. Also, when we observe the dendrites, we can see that few dendrites are more think than others. Dendrites with more thickness will give more impulses than the less thick ones.Durning the initial years, kids consume lots of data like visual data, audio, sensory data etc., Since child consumes lots of data, our biological algorithm creates new connections based on the data that child has consumed. Kids born on different countries, conditions or circumstances will have different neuron connections. For example, a kid born in India and Canada will have different connections established because of their language / culture / parents etc.,How thickness of connections are formed?When a kid touches a hot object, it gives child a pain and forms a strong neural connection, so that when there is a hot object near to kid, it gives a strong signal that dont touch the object. Similarly, when a kid is born in Canada, he knows how snow looks and feels but kid born in India dont have that connection available.We can write activation function as, This function is similar to Logistic RegressionWhen there is no connection between neurons, then weight of that connection is 0Bottomline:When we learn a new thing, a new connection will be formed between set of neurons and weights / thickness will be established.Hope you like this article and please share your feedback." }, { "title": "Distance Measures", "url": "/TheDataLearning/posts/Distance-Measures/", "categories": "Tutorial, Machine Learning", "tags": "Machine Learning, Distance Measure, Euclidean Distance, Manhattan Distance, Minkowski Distance, Hamming Distance", "date": "2021-04-04 23:25:00 +0800", "snippet": "In this article, we will look into different distance measures we will use in Machine Learning.1. Euclidean Distance (L2):Euclidean Distance is most frequently used distance measure. If we observe the above picture, variable ‘d’ is called the Euclidean distance (L2). It is called the shortest distance from X1 to X2.In above picture, we have two features, f1 and f2 and two datapoints in 2D, X1 and X2. Euclidean distance can be formulated as 2. Manhattan Distance (L1):Manhattan Distance is next frequently used and simple distance measure.From above graph, Manhattan distance can be formulated as, 3. Minkowski Distance (LP):Minkowski Distance is the generalized distance measure and can be formulated as, When p=1 in Minkowski Distance, it becomes Manhattan Distance and when p=2, it becomes Euclidean distanceManhattan distance is also called as L1-Norm and Euclidean distance is called as L2-Norm4. Hamming Distance:Hamming distance is widely used in text processing and it gives us the # of difference of values between dimensions in vectors.Hamming distance will be used in Gene sequence. Above sequence generates value of 2 as there is difference of values in 7 and 10 dimensionsThere are other measures as well and we will understand about few of them in the future. One such important and widely used measure is Cosine Distance and Cosine similarity, we will see this in upcoming articles.Bottomline:There are many distance measures that are used in Machine Learning and few of them are Manhattan distance, Euclidean distance, Minkowski distance and Hamming distance. There are other distance measures also which are widely used and we will see them in future articles.Hope you like this article and please share your feedback." }, { "title": "Classification and Regression", "url": "/TheDataLearning/posts/Classification-and-regression/", "categories": "Tutorial, Machine Learning", "tags": "Machine Learning, Classification, Regression", "date": "2021-04-04 23:25:00 +0800", "snippet": "In this article, we will look into two different kinds of Machine learning algorithms, Classification and Regression models.The main objective of Machine learning model is to find a function f, such that when a query point (x_q) is passed thru the function f, it will return desired output (y_q_^)Classification:Lets consider an example for understanding the classification problems. Say, we want to classify reviews in an eCommerce website and typically we need to classify each review as positive review, negative review or neutral review. This type of problem is called Classification problem.Here when we look closely, we are classifying the datapoints into set of classes like positive, negative, neutral etc.. This kind of technique is called Classification.We can interpret classification dataset as below: where x is input data and y is the output class.Regression:Consider this example for understanding regression problems. Say, we want to predict the heights of students in a school. Here our predicted value is a real number since height is a real number.We can interpret regression dataset as below: where x is input data and y is a real valued numberDid you observe difference between Classification and Regression ?If you observe closely on the dataset interpretations for Classification and Regression, we can see the difference in the output variable ‘y’.In Classification, ‘y’ is a finite number where as in Regression, ‘y’ is a real valued number, which is a difference on very high level. We will understand more differences as we go on.Bottomline:On simple and very highlevel terms, difference between Classification and Regression comes to difference between finite integer and Real valued number 😃Hope you like this article and feel free to share your comments." }, { "title": "Different techniques to convert words to vectors", "url": "/TheDataLearning/posts/techniques-to-convert-words-to-vectors/", "categories": "Tutorial, Machine Learning", "tags": "Machine Learning, Bag of Words, BOW, TF-IDF, TFIDF, Word2Vec", "date": "2021-04-03 23:25:00 +0800", "snippet": "In Machine Learning, we want to convert words into vectors to fully utilize the mathematical functions for the model.There are various techniques using which we can convert words into vectors. We will look into those techniques in this article.Below are few techniques which can convert words to vectors: Bag of Words (BOW) TF-IDF Vectorizer Word2Vec Input TextLets say we have 4 sentences which we want to convert to vectors:&amp;gt; This headphone is amazing&amp;gt; Noise Cancelling in this headphone is really awesome&amp;gt; This headphone is not good&amp;gt; This headphone is TrulyWireless and works as described in the descriptionBag of Words (BoW)This is the simplest way to convert text to a vector. Basic idea of this technique is store all unique words in a list and for each sentence we will create a vector of length same as unique words. This creates a sparse vector where most of the values in the vector are zeros.From our above example, our Bag of unique words contains: {This, headphone, is, amazing, Noise, Cancelling, in, really, awesome, not, good, TrulyWireless, and, works, as, described, the, description}Here we have 18 unique words in the bag, so we will represent each of the sentense in a vector of length 18. Representation of sentence 1 -&amp;gt; This headphone is amazing -&amp;gt; [1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0]Similarly other sentences can be represented as, Noise Cancelling in this headphone is really awesome -&amp;gt; [1,1,1,0,1,1,1,1,1,0,0,0,0,0,0,0,0,0] This headphone is not good -&amp;gt; [1,1,1,0,0,0,0,0,0,1,1,0,0,0,0,0,0]Same is repeated for other sentenceTF-IDF VectorizerBag of Words simply convert each word into a vector without considering the importance of the word. In TF-IDF, we will consider the frequency of word into consideration.TF (Term Frequency):How often a word occurs in corpus. If a word occurs multiple times, then TF of the word will be highIDF (Inverse Document Frequency):How rare a word occurs in corpus. If a word is rare, then the IDF of the word will be highBy combining TF-IDF, we are giving importance to rare word in corpus and frequency of occurance in current sentenceFrom our above example, our unique words are: {This, headphone, is, amazing, Noise, Cancelling, in, really, awesome, not, good, TrulyWireless, and, works, as, described, the, description}For computing the TF-IDF of a word in Sentence 1, consider ‘This’ wordTF(&#39;This&#39;) : 1/4IDF(&#39;This&#39;): log(4/4)TF-IDF(&#39;This&#39;)=TF(&#39;This&#39;)*IDF(&#39;This&#39;)=(1/4)*(log(1))=0Here word ‘This’ occurs very frequently in the document corpus and is not a important word and hence TF-IDF of ‘This’ is 0so, we will update TF-IDF of Sentence 1 as -&amp;gt; This headphone is amazing -&amp;gt;[TF-IDF(&#39;This&#39;),TF-IDF(&#39;headphone&#39;),TF-IDF(&#39;is&#39;),TF-IDF(&#39;amazing&#39;),0,0,0,0,0,0,0,0,0,0,0,0,0,0]Word2VecWord2Vec considers the semantic meaning and generates vectors for each word. Word2Vec considers the context and relation between the words. Distance between vectors of similar words is less. For example, distance between vectors generated by Word2Vec for King and Queen will be similar to distance between vectors for Man and Woman.Word2Vec learns the vectors from large document corpus.Conclusion:Using above techniques, we can convert words into vectors on which we can apply transformation that are useful for machine learning.I will try to create blog for each of the techniques more elaborately." } ]
